# MFA configuration optimized for MNIST
defaults:
  - mfa
  - _self_

latent_dim: 10
n_clusters: 50
init_scale: 0.01
min_var: 0.01

trainer:
  lr: 1e-5
  n_epochs: 200   
  # batch_size: 500
  batch_steps: 1000
  grad_clip: 1.0 

  # Regularization
  l1_reg: 0 # 1e-3
  l2_reg: 0 # 1e-4
  upr_prs_reg: 0 # 1e-3
  lwr_prs_reg: 0 # 1e-3

  min_prob: 1e-3
  obs_min_var: 1e-4
  lat_min_var: 1e-6

  # Jitter (optional, for additional stability)
  obs_jitter_var: 0.0
  lat_jitter_var: 0.0

analyses:
  generative_samples:
    enabled: true
    n_samples: 100
  cluster_statistics:
    enabled: true
  co_assignment_hierarchy:
    enabled: true
  co_assignment_merge:
    enabled: true
  optimal_merge:
    enabled: false
